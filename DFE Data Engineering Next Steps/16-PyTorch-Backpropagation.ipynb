{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation in PyTorch\n",
    "\n",
    "To explain backpropagation let us look at the below compoisition of two functions:\n",
    "\n",
    "$w = g(f(x))$\n",
    "\n",
    "Where the function requires the set of images of $f$ to be the domain of $g$.<br>\n",
    "When training a Neural Network, we want to minimise the use of this kind of (loss) function.<br>\n",
    "We have done this previously by computing gradients, namely by computing the derivative of the loss with respect to the tensor $x$.<br>\n",
    "In this instance, we want to compute:\n",
    "$$\\frac{dw}{dx} = \\frac{dw}{dy} \\frac{dy}{dx}$$\n",
    "\n",
    "We have two tensors, $x$ and $y$, and w is the application of a differentiable function with respect to $y$.<br>\n",
    "\n",
    "## Local gradients\n",
    "\n",
    "Every time we compute a gradient we are implicitly performing an operation on the computational graph.\n",
    "\n",
    "In our example, this translates into the multiplication of the two tensors, which means we can compute independently the partial derivative of $w$ with respect to $y$ and the partial derivative of $y$ with respect to $x$.<br>\n",
    "But those two quantivites are called local gradients, and play a key role in backpropagation.<br>\n",
    "i.e. local gradients are the partial derivatives performed on the computational graph operation.\n",
    "\n",
    "The following is an Computation Graph of an Ordinary Least Square Model:\n",
    "$$^{x} _{w} \\Rightarrow \\hat{y} = w * x \\Rightarrow l = ( \\hat{y} - y ) \\Rightarrow l^{2} \\Rightarrow Loss$$ \n",
    "\n",
    "We have two inputs, tensor $x$ and tensor $w$ denoting the weights of the model and the predicted value is obtained $\\hat{y}$ as a linear combination of those weights and $x$, typically denotes the set of features.<br>\n",
    "We then define a loss function to evaluate the model performance.<br>\n",
    "\n",
    "We are splitting the calculation of ordinary least squares:\n",
    "1. define the difference between the prediction ($\\hat{y}$) and actual value ($y$),\n",
    "2. squaring the tensor ($l^{2}$) to get the final $Loss$.\n",
    "\n",
    "## Minimising Loss\n",
    "\n",
    "Assuming we have performed the necessary forward step, computing the loss with respect to the inpur tensors, we then need to calculate the local gradients at each note inside the computational graph:\n",
    "\n",
    "$$\\frac{dLoss}{dl} , \\frac{dl}{d\\hat{y}} , \\frac{d\\hat{y}}{dw}$$\n",
    "\n",
    "We use these partial derivatives to get the partial derivative of the loss with respect to the input via $w$ via backpropagation, or better by a simple application of the chain rule.\n",
    "\n",
    "We do not need to compute the partial derivative of $l$ with respect to $y$ or the partial derivative of $\\hat{y}$ with respect to $x$ becuase they are fixed tensors in a typical OLD application.<br>\n",
    "In other words, both $x$ and $y$ are given, and so when minimising a loss function, that which changes is the set of parameters we wish to estimate - in our case the weights $w$, and not the features.<br>\n",
    "That is why we do not compute the local gradient of $\\hat{y}$ with respect to $x$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(1.0)\n",
    "y = torch.tensor(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor(1.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = w * x\n",
    "loss = (y_hat - y) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward step: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Forward step: {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From an algebraic point of view, we can see that $x$ is 1 and $w$ is 1 therefore their product is 1.<br>\n",
    "The square of -1 is also 1, which is the $loss$.<br>\n",
    "So everything is working as expected.\n",
    "\n",
    "A minimizing process requires a forward step and then a backward step.<br>\n",
    "To perform backpropgation, we apply the backwarrd function on the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backward Step: -2.0\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "print(f'Backward Step: {w.grad}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having the weights based on a learning rate, we continute the minimisation phase with a new forward and backward step until a minimum is reached.\n",
    "\n",
    "We continue updating weights but without this being part of the computation graph.<br>\n",
    "i.e. we set the gradient to zero after updating the weights (at each epoch/step).\n",
    "\n",
    "We wrap the update operation inside `no_grad` method and specify the weights are updated based on the product between a learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0200, requires_grad=True)\n",
      "tensor(-2.)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    w -= 0.01 * w.grad\n",
    "    print(w) # 1.02\n",
    "print(w.grad) # -2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we are learning the weights at each step with a particular learning rate, we expected 1.02.<br> \n",
    "On the below, we are setting the gradient to zero at each step and expected this to be -2.0 - as we computed before in the first step.\n",
    "\n",
    "In a Neural Network training phase, we will have to perform several forward and backward passes.<br>\n",
    "But the logic will remain the same.<br>\n",
    "We have an update on the weights based on the learning rate and on the gradient that was computed and thanks to this highlighted operation, the gradients function is not part of the computation graph."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
